# ge_listings_telegram_bot.py
# -*- coding: utf-8 -*-
"""
–¢–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç –¥–ª—è –æ–±—ä—è–≤–ª–µ–Ω–∏–π (myhome.ge, home.ss.ge).

–ù–æ–≤–æ–µ:
- /status: —Å–≤–æ–¥–∫–∞ –∑–∞ –¥–µ–Ω—å/–Ω–µ–¥–µ–ª—é/–º–µ—Å—è—Ü (–ø–æ posted_at).
- –ù–∞ –ø–æ–≤—Ç–æ—Ä–Ω—É—é —Å—Å—ã–ª–∫—É –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è: –±–æ—Ç —Å–Ω–∞—á–∞–ª–∞
  –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞—Ä—Ç–æ—á–∫—É —Å –∫–Ω–æ–ø–∫–∞–º–∏ –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —É–¥–∞–ª–∏—Ç—å –∏–∑ –≥—Ä—É–ø–ø—ã.
  –ü–∞—Ä—Å–∏–Ω–≥ –¥–µ–ª–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä –Ω–∞–∂–∞–ª ¬´–û—Ç–ø—Ä–∞–≤–∏—Ç—å¬ª –∏–ª–∏ ¬´–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å¬ª.

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
  pip install aiogram>=3 httpx[http2] pillow
  # —Å–∫—Ä–∞–ø–µ—Ä —Ä—è–¥–æ–º: scrape_ge_listings.py
–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
  BOT_TOKEN, TARGET_GROUP_ID, DB_PATH (–æ–ø—Ü.)
"""

from __future__ import annotations

import asyncio
import json
import os
import re
import sqlite3
from contextlib import closing
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from io import BytesIO
from typing import Any, Dict, List, Optional, Tuple
from urllib.parse import urlsplit, urlunsplit

import httpx
from PIL import Image

from aiogram import Bot, Dispatcher, F, types
from aiogram.enums import ParseMode
from aiogram.filters import Command, CommandStart
from aiogram.types import (
    InlineKeyboardMarkup,
    CallbackQuery,
    Message,
    InputMediaPhoto,
    BufferedInputFile,
)
from aiogram.utils.keyboard import InlineKeyboardBuilder
from aiogram.exceptions import TelegramBadRequest

# –≤–∞—à —Å–∫—Ä–∞–ø–µ—Ä
from scrape_ge_listings import get_extractor  # type: ignore


BOT_TOKEN = os.getenv("BOT_TOKEN", "")
TARGET_GROUP_ID = int(os.getenv("TARGET_GROUP_ID", "0"))
DB_PATH = os.getenv("DB_PATH", "bot_data.sqlite")
ALBUM_GET_TIMEOUT = float(os.getenv("BOT_ALBUM_GET_TIMEOUT", "60.0"))


# ============== –ë–î ==============

def _db() -> sqlite3.Connection:
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn

def init_db() -> None:
    with closing(_db()) as conn, conn:
        conn.executescript(
            """
            CREATE TABLE IF NOT EXISTS postings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source TEXT NOT NULL,
                listing_id TEXT,
                canonical_url TEXT NOT NULL,
                title TEXT,
                summary_ru TEXT,
                created_at INTEGER NOT NULL,
                posted_at INTEGER,
                deleted_at INTEGER,
                chat_id INTEGER,
                message_ids TEXT,
                status TEXT NOT NULL DEFAULT 'draft'
            );
            CREATE UNIQUE INDEX IF NOT EXISTS ux_posting_key
              ON postings(source, listing_id, canonical_url);
            """
        )
        # –º—è–≥–∫–∞—è –º–∏–≥—Ä–∞—Ü–∏—è: —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∏ –µ—Å—Ç—å (–µ—Å–ª–∏ –±–∞–∑–∞ —Å—Ç–∞—Ä–∞—è)
        cols = {r["name"] for r in conn.execute("PRAGMA table_info(postings)")}
        for need in ("posted_at", "deleted_at"):
            if need not in cols:
                conn.execute(f"ALTER TABLE postings ADD COLUMN {need} INTEGER")

def db_find_by_keys(source: str, listing_id: Optional[str], canonical_url: str) -> Optional[sqlite3.Row]:
    q = """
      SELECT * FROM postings
      WHERE (source=? AND listing_id IS ? AND canonical_url=?)
         OR (source=? AND listing_id=?)
         OR (canonical_url=?)
      ORDER BY id DESC LIMIT 1
    """
    with closing(_db()) as conn:
        cur = conn.execute(q, (source, listing_id, canonical_url, source, listing_id, canonical_url))
        return cur.fetchone()

def db_insert_draft(info: Dict[str, Any]) -> int:
    with closing(_db()) as conn, conn:
        cur = conn.execute(
            """INSERT INTO postings(source, listing_id, canonical_url, title, summary_ru, created_at, status)
               VALUES(?,?,?,?,?,?, 'draft')""",
            (
                info["source"], info.get("listing_id"), info["canonical_url"],
                info.get("title"), info.get("summary_ru"),
                int(datetime.now(tz=timezone.utc).timestamp()),
            ),
        )
        return int(cur.lastrowid)

def db_update_brief(row_id: int, title: Optional[str], summary_ru: Optional[str]) -> None:
    with closing(_db()) as conn, conn:
        conn.execute(
            "UPDATE postings SET title=COALESCE(?, title), summary_ru=COALESCE(?, summary_ru) WHERE id=?",
            (title, summary_ru, row_id),
        )

def db_mark_posted(row_id: int, chat_id: int, message_ids: List[int]) -> None:
    with closing(_db()) as conn, conn:
        now = int(datetime.now(tz=timezone.utc).timestamp())
        conn.execute(
            "UPDATE postings SET status='posted', posted_at=?, chat_id=?, message_ids=? WHERE id=?",
            (now, chat_id, json.dumps(message_ids, ensure_ascii=False), row_id),
        )

def db_mark_deleted(row_id: int) -> None:
    with closing(_db()) as conn, conn:
        now = int(datetime.now(tz=timezone.utc).timestamp())
        conn.execute("UPDATE postings SET status='deleted', deleted_at=? WHERE id=?", (now, row_id))

def db_recent(limit: int = 10) -> List[sqlite3.Row]:
    with closing(_db()) as conn:
        cur = conn.execute("SELECT * FROM postings ORDER BY id DESC LIMIT ?", (limit,))
        return cur.fetchall()

def db_stats_window(since_ts: int) -> Dict[str, int]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç counts –¥–ª—è —Å—Ç–∞—Ç—É—Å–æ–≤ –≤ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ [since, now] –ø–æ –¥–∞—Ç–µ posted_at."""
    with closing(_db()) as conn:
        # –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ
        posted = conn.execute(
            "SELECT COUNT(*) FROM postings WHERE status='posted' AND posted_at>=?",
            (since_ts,),
        ).fetchone()[0]
        # —É–¥–∞–ª–µ–Ω–æ
        deleted = conn.execute(
            "SELECT COUNT(*) FROM postings WHERE status='deleted' AND deleted_at>=?",
            (since_ts,),
        ).fetchone()[0]
        # —á–µ—Ä–Ω–æ–≤–∏–∫–∏ (—Å–æ–∑–¥–∞–Ω—ã –∑–∞ –æ–∫–Ω–æ –∏ –Ω–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω—ã)
        drafts = conn.execute(
            "SELECT COUNT(*) FROM postings WHERE status='draft' AND created_at>=?",
            (since_ts,),
        ).fetchone()[0]
    return {"posted": posted, "deleted": deleted, "drafts": drafts}


# ============== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ ==============

def ensure_ru_myhome(url: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Å—Å—ã–ª–∫–∏ myhome.ge –∏ home.ss.ge –Ω–∞ —Ä—É—Å—Å–∫—É—é –≤–µ—Ä—Å–∏—é."""
    u = urlsplit(url)
    host = u.netloc
    if "myhome.ge" in host or "home.ss.ge" in host:
        path = u.path
        if not path.startswith("/ru/"):
            if path.startswith(("/ka/", "/en/", "/az/", "/am/")):
                path = "/ru/" + path.split("/", 2)[2]
            else:
                path = "/ru" + path
        path = re.sub(r"/{2,}", "/", path)
        return urlunsplit((u.scheme, host, path, u.query, u.fragment))
    return url

def pick_first_url(text: str) -> Optional[str]:
    m = re.search(r"https?://[^\s]+", text or "")
    return m.group(0) if m else None

def currency_symbol(cur: Optional[str]) -> str:
    if not cur:
        return ""
    return {"USD": "$", "EUR": "‚Ç¨", "GEL": "‚Çæ"}.get(cur.upper(), cur)

def build_summary_ru(data: Dict[str, Any]) -> str:
    rooms = data.get("rooms")
    beds = data.get("bedrooms")
    floor = data.get("floor")
    floors = data.get("floors_total")
    area = data.get("area_m2")
    price = data.get("price", {}) or {}
    loc = data.get("location") or data.get("address_line") or ""
    cur = price.get("currency")
    amt = price.get("amount")
    head = []
    if amt:
        head.append(f"–ê—Ä–µ–Ω–¥–∞ {currency_symbol(cur)}{amt}")
    if loc:
        head.append(str(loc))
    lines = [" ‚Äì ".join(head) if head else "–ê—Ä–µ–Ω–¥–∞"]
    if data.get("address_line"):
        lines.append(str(data["address_line"]))
    second = []
    if rooms:
        second.append(f"{rooms} –ö–æ–º–Ω–∞—Ç—ã")
    if beds:
        second.append(f"{beds} –°–ø–∞–ª—å–Ω—è")
    if second:
        lines.append(", ".join(second))
    third = []
    if floor and floors:
        third.append(f"{floor}/{floors} –≠—Ç–∞–∂–µ–π")
    elif floor:
        third.append(f"{floor} —ç—Ç–∞–∂")
    if area:
        third.append(f"{area} –º¬≤")
    if third:
        lines.append(", ".join(third))
    return "\n".join(lines)

def quick_source_and_id(url: str) -> Tuple[str, Optional[str]]:
    """–ë–µ–∑ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å (source, listing_id) –∏–∑ URL."""
    u = urlsplit(url)
    host = u.netloc.lower()
    if "myhome.ge" in host:
        m = re.search(r"/pr/(\d+)", u.path)
        return ("myhome.ge", m.group(1) if m else None)
    if "ss.ge" in host:
        m = re.search(r"-(\d{6,})/?$", u.path)
        return ("home.ss.ge", m.group(1) if m else None)
    return (host, None)

async def download_and_prepare_album(urls: List[str], client: httpx.AsyncClient, cap_text: Optional[str]) -> List[InputMediaPhoto]:
    media: List[InputMediaPhoto] = []
    urls = urls[:10]  # —Ç–µ–ª–µ–≥–∞ –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç >10
    for i, u in enumerate(urls):
        try:
            r = await client.get(u, timeout=ALBUM_GET_TIMEOUT, follow_redirects=True)
            r.raise_for_status()
            ctype = r.headers.get("content-type", "")
            content = r.content
            if ".webp" in u.lower() or "image/webp" in ctype.lower():
                im = Image.open(BytesIO(content)).convert("RGB")
                buf = BytesIO()
                im.save(buf, format="JPEG", quality=90)
                buf.seek(0)
                file = BufferedInputFile(buf.read(), filename=f"img_{i+1:02d}.jpg")
            else:
                file = BufferedInputFile(content, filename=f"img_{i+1:02d}.jpg")
            if i == 0:
                cap = (cap_text or "")[:1024]
                media.append(InputMediaPhoto(media=file, caption=cap, parse_mode=ParseMode.HTML))
            else:
                media.append(InputMediaPhoto(media=file))
        except Exception:
            continue
    return media

@dataclass
class ScrapeResult:
    source: str
    listing_id: Optional[str]
    canonical_url: str
    title: Optional[str]
    summary_ru: str
    photos: List[str]
    phones: List[str]
    raw: Dict[str, Any]

async def scrape_listing(url: str) -> ScrapeResult:
    url = ensure_ru_myhome(url)
    extractor = get_extractor(url)
    listing = await asyncio.to_thread(extractor.extract)
    data = listing.dict()
    canonical_url = ensure_ru_myhome(data.get("url") or url)
    photos = data.get("photos") or []
    summary_ru = data.get("summary_ru") or build_summary_ru(data)
    return ScrapeResult(
        source=data.get("source") or "",
        listing_id=data.get("listing_id"),
        canonical_url=canonical_url,
        title=data.get("title"),
        summary_ru=summary_ru,
        photos=photos,
        phones=data.get("phones") or [],
        raw=data,
    )


# ============== –¢–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç ==============

dp = Dispatcher()
bot = Bot(BOT_TOKEN, parse_mode=ParseMode.HTML)

AWAIT_EDIT: Dict[int, str] = {}  # user_id -> canonical_url

def build_keyboard(row_id: int, exists_posted: bool) -> InlineKeyboardMarkup:
    kb = InlineKeyboardBuilder()
    kb.button(text="üì§ –û—Ç–ø—Ä–∞–≤–∏—Ç—å", callback_data=f"send:{row_id}")
    kb.button(text="‚úèÔ∏è –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å", callback_data=f"edit:{row_id}")
    if exists_posted:
        kb.button(text="üóë –£–¥–∞–ª–∏—Ç—å –∏–∑ –≥—Ä—É–ø–ø—ã", callback_data=f"delete:{row_id}")
    kb.adjust(2, 1)
    return kb.as_markup()

@dp.message(CommandStart())
async def on_start(m: Message):
    await m.answer(
        "–ü—Ä–∏—à–ª–∏—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ (myhome.ge / home.ss.ge).\n"
        "–ë–æ—Ç —Å–æ–±–µ—Ä—ë—Ç —Ñ–æ—Ç–æ –∏ –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, –ª–∏–±–æ ‚Äî –µ—Å–ª–∏ —Ç–∞–∫–∞—è —Å—Å—ã–ª–∫–∞ —É–∂–µ –ø—É–±–ª–∏–∫–æ–≤–∞–ª–∞—Å—å ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏—Ç —É–¥–∞–ª–∏—Ç—å –ø–æ—Å—Ç –∏–∑ –≥—Ä—É–ø–ø—ã."
    )

@dp.message(Command("list"))
async def on_list(m: Message):
    rows = db_recent(10)
    if not rows:
        await m.answer("–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç.")
        return
    text = "\n".join(f"#{r['id']} [{r['status']}] {r['canonical_url']}" for r in rows)
    await m.answer(text)

@dp.message(Command("status"))
async def on_status(m: Message):
    now = datetime.now(tz=timezone.utc)
    def pack(delta_days: int) -> str:
        since = int((now - timedelta(days=delta_days)).timestamp())
        s = db_stats_window(since)
        return f"–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {s['posted']}, –£–¥–∞–ª–µ–Ω–æ: {s['deleted']}, –ß–µ—Ä–Ω–æ–≤–∏–∫–∏: {s['drafts']}"
    msg = (
        "<b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</b>\n"
        f"–ó–∞ –¥–µ–Ω—å:   {pack(1)}\n"
        f"–ó–∞ –Ω–µ–¥–µ–ª—é: {pack(7)}\n"
        f"–ó–∞ –º–µ—Å—è—Ü:  {pack(30)}"
    )
    await m.answer(msg)

@dp.message(F.text.func(lambda t: bool(pick_first_url(t or ""))))
async def on_link(m: Message):
    url_raw = pick_first_url(m.text or "")
    assert url_raw
    url = ensure_ru_myhome(url_raw)
    source, lid_guess = quick_source_and_id(url)

    # 1) –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–µ–π –ø–æ URL/ID ‚Äî –±–µ–∑ –ø–∞—Ä—Å–∏–Ω–≥–∞.
    row = db_find_by_keys(source, lid_guess, url)
    if row and row["status"] == "posted":
        # –£–∂–µ –ø—É–±–ª–∏–∫–æ–≤–∞–ª–æ—Å—å ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –ø–∞—Ä—Å–∏–º, –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º —É–¥–∞–ª–∏—Ç—å/–ø–µ—Ä–µ—Å–ª–∞—Ç—å/—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
        text = (
            f"‚ö†Ô∏è –¢–∞–∫–∞—è —Å—Å—ã–ª–∫–∞ —É–∂–µ –ø—É–±–ª–∏–∫–æ–≤–∞–ª–∞—Å—å.\n\n"
            f"<b>{row['title'] or '–û–±—ä—è–≤–ª–µ–Ω–∏–µ'}</b>\n"
            f"{(row['summary_ru'] or '')}"
        )
        await m.answer(text, reply_markup=build_keyboard(int(row["id"]), exists_posted=True))
        return

    await m.answer("–°–æ–±–∏—Ä–∞—é –¥–∞–Ω–Ω—ã–µ‚Ä¶")
    # 2) –ï—Å–ª–∏ –Ω–æ–≤—ã–π –ª–æ—Ç –∏–ª–∏ —á–µ—Ä–Ω–æ–≤–∏–∫ ‚Äî –ø–∞—Ä—Å–∏–º –¥–ª—è –ø—Ä–µ–≤—å—é –∏ –∑–∞–≤–æ–¥–∏–º draft.
    try:
        sr = await scrape_listing(url)
    except Exception as e:
        await m.answer(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ: {e}")
        return

    # –∑–∞–ø–∏—Å—å (draft) ‚Äî –ª–∏–±–æ –æ–±–Ω–æ–≤–∏–º –∫—Ä–∞—Ç–∫–∏–µ –ø–æ–ª—è, –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å —á–µ—Ä–Ω–æ–≤–∏–∫
    exists = db_find_by_keys(sr.source, sr.listing_id, sr.canonical_url)
    if exists:
        row_id = int(exists["id"])
        db_update_brief(row_id, sr.title, sr.summary_ru)
        exists_posted = exists["status"] == "posted"
    else:
        row_id = db_insert_draft(
            {
                "source": sr.source,
                "listing_id": sr.listing_id,
                "canonical_url": sr.canonical_url,
                "title": sr.title,
                "summary_ru": sr.summary_ru,
            }
        )
        exists_posted = False

    # –ø—Ä–µ–≤—å—é –∞–ª—å–±–æ–º–æ–º –æ–ø–µ—Ä–∞—Ç–æ—Ä—É
    async with httpx.AsyncClient(headers={"User-Agent": "ListingBot/1.0"}) as client:
        album = await download_and_prepare_album(
            sr.photos,
            client,
            f"<b>{sr.title or ''}</b>\n{sr.summary_ru}"
        )
    if album:
        try:
            await bot.send_media_group(chat_id=m.chat.id, media=album)
        except TelegramBadRequest:
            await m.answer_photo(album[0].media, caption=album[0].caption)

    text = (
        f"<b>{sr.title or '–û–±—ä—è–≤–ª–µ–Ω–∏–µ'}</b>\n{sr.summary_ru}"
    )
    await m.answer(text, reply_markup=build_keyboard(row_id, exists_posted))

# --- callbacks ---

async def _load_row(row_id: int) -> Optional[sqlite3.Row]:
    with closing(_db()) as conn:
        cur = conn.execute("SELECT * FROM postings WHERE id=?", (row_id,))
        return cur.fetchone()

@dp.callback_query(F.data.startswith("send:"))
async def on_send(cb: CallbackQuery):
    row_id = int(cb.data.split(":")[1])
    row = await _load_row(row_id)
    if not row:
        await cb.answer("–ù–µ –Ω–∞—à—ë–ª –∑–∞–ø–∏—Å—å", show_alert=True); return

    if row["status"] == "posted":
        await cb.message.answer("–≠—Ç–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ. –£–¥–∞–ª–∏—Ç—å –ø—É–±–ª–∏–∫–∞—Ü–∏—é –∏–∑ –≥—Ä—É–ø–ø—ã?",
                                reply_markup=build_keyboard(row_id, exists_posted=True))
        await cb.answer(); return

    # –ø–∞—Ä—Å–∏–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —Ä–µ–∞–ª—å–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–µ
    try:
        sr = await scrape_listing(row["canonical_url"])
    except Exception as e:
        await cb.message.answer(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ: {e}"); await cb.answer(); return

    async with httpx.AsyncClient(headers={"User-Agent": "ListingBot/1.0"}) as client:
        album = await download_and_prepare_album(
            sr.photos,
            client,
            f"<b>{sr.title or ''}</b>\n{sr.summary_ru}"
        )
    if not album:
        await cb.message.answer("–ù–µ—Ç —Ñ–æ—Ç–æ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏."); await cb.answer(); return

    msgs: List[Message] = await bot.send_media_group(chat_id=TARGET_GROUP_ID, media=album)
    message_ids = [m.message_id for m in msgs]
    db_mark_posted(row_id, TARGET_GROUP_ID, message_ids)
    # –æ–±–Ω–æ–≤–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫/summary (–º–æ–≥–ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å—Å—è)
    db_update_brief(row_id, sr.title, sr.summary_ru)

    await cb.message.answer("‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ –≥—Ä—É–ø–ø—É.")
    await cb.answer()

@dp.callback_query(F.data.startswith("edit:"))
async def on_edit(cb: CallbackQuery):
    row_id = int(cb.data.split(":")[1])
    row = await _load_row(row_id)
    if not row:
        await cb.answer("–ù–µ –Ω–∞—à—ë–ª –∑–∞–ø–∏—Å—å", show_alert=True); return
    # –∑–∞–ø–æ–º–Ω–∏–º, —á—Ç–æ –∂–¥—ë–º —Ç–µ–∫—Å—Ç
    AWAIT_EDIT[cb.from_user.id] = row["canonical_url"]
    await cb.message.answer("–ü—Ä–∏—à–ª–∏—Ç–µ —Ç–µ–∫—Å—Ç. –ï–≥–æ –ø–æ—Å—Ç–∞–≤–ª—é –∫–∞–∫ –ø–æ–¥–ø–∏—Å—å –∫ –∞–ª—å–±–æ–º—É –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤ –≥—Ä—É–ø–ø—É.")
    await cb.answer()

@dp.message(F.from_user.func(lambda u: u.id in AWAIT_EDIT))
async def on_edit_text(m: Message):
    url = AWAIT_EDIT.pop(m.from_user.id)
    row = db_find_by_keys(*quick_source_and_id(url), ensure_ru_myhome(url))
    if not row:
        await m.answer("–ó–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–∏—à–ª–∏—Ç–µ —Å—Å—ã–ª–∫—É –µ—â—ë —Ä–∞–∑."); return
    try:
        sr = await scrape_listing(url)
    except Exception as e:
        await m.answer(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ: {e}"); return
    caption = (m.text or "").strip()[:1024]
    async with httpx.AsyncClient(headers={"User-Agent": "ListingBot/1.0"}) as client:
        album = await download_and_prepare_album(sr.photos, client, caption)
    if not album:
        await m.answer("–ù–µ—Ç —Ñ–æ—Ç–æ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏."); return
    msgs = await bot.send_media_group(chat_id=TARGET_GROUP_ID, media=album)
    message_ids = [mm.message_id for mm in msgs]
    db_mark_posted(int(row["id"]), TARGET_GROUP_ID, message_ids)
    await m.answer("‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ –≥—Ä—É–ø–ø—É —Å –≤–∞—à–∏–º —Ç–µ–∫—Å—Ç–æ–º.")

@dp.callback_query(F.data.startswith("delete:"))
async def on_delete(cb: CallbackQuery):
    row_id = int(cb.data.split(":")[1])
    row = await _load_row(row_id)
    if not row or row["status"] != "posted":
        await cb.answer("–ü—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω–µ—Ç –∏–ª–∏ —É–∂–µ —É–¥–∞–ª–µ–Ω–∞."); return
    chat_id = int(row["chat_id"])
    ids = json.loads(row["message_ids"] or "[]")
    ok_all = True
    for mid in ids:
        try:
            await bot.delete_message(chat_id=chat_id, message_id=int(mid))
        except TelegramBadRequest:
            ok_all = False
    db_mark_deleted(row_id)
    await cb.message.answer("üóë –£–¥–∞–ª–µ–Ω–æ –∏–∑ –≥—Ä—É–ø–ø—ã." if ok_all else "–£–¥–∞–ª–∏–ª –Ω–µ –≤—Å—ë (–ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –±–æ—Ç–∞).")
    await cb.answer()

# ============== Main ==============

async def main():
    if not BOT_TOKEN or not TARGET_GROUP_ID:
        raise SystemExit("–£–∫–∞–∂–∏—Ç–µ BOT_TOKEN –∏ TARGET_GROUP_ID –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
    init_db()
    print("Bot is running‚Ä¶")
    await dp.start_polling(bot)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        pass
